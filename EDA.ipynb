{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Sharing Demand：自転車利用数予測\n",
    "https://www.kaggle.com/c/bike-sharing-demand\n",
    "## Washington, D.C. の過去のレンタル自転車の利用パターン情報と気象データから、レンタル自転車の利用数を予測するモデルを作成する\n",
    "\n",
    "### 評価指標：RMSLE\n",
    "$$\n",
    "\\sqrt{\\frac{1}{n}\\sum_{i=0}^{n}(\\log(p_i+1)-\\log(a_i+1))^2}\n",
    "$$\n",
    "### data field\n",
    "**datetime** - hourly date + timestamp  \n",
    "**season** -  1 = spring, 2 = summer, 3 = fall, 4 = winter  \n",
    "**holiday** - whether the day is considered a holiday  \n",
    "**workingday** - whether the day is neither a weekend nor holiday  \n",
    "**weather** - 1: Clear, Few clouds, Partly cloudy, Partly cloudy  \n",
    "2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  \n",
    "3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds  \n",
    "4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog  \n",
    "**temp** - temperature in Celsius  \n",
    "**atemp** - \"feels like\" temperature in Celsius  \n",
    "**humidity** - relative humidity  \n",
    "**windspeed** - wind speed  \n",
    "**casual** - number of non-registered user rentals initiated  \n",
    "**registered** - number of registered user rentals initiated  \n",
    "**count** - number of total rentals  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み関連\n",
    "ここら辺は特段難しいことはやってないので、基本コピペで問題ないです。  \n",
    "C言語触ったことある人だったら、初見でもなんとなくやってることはわかるのではと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = '../input/train.csv'\n",
    "TEST_DATA = '../input/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse_datesで指定した列をdatetime型で読み込んでおくと、後々便利"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    df = pd.read_csv(path, parse_dates=[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    df = read_csv(TRAIN_DATA)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    df = read_csv(TEST_DATA)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_train_data()\n",
    "test = load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のデータは欠損値がありません。素晴らしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering\n",
    "datetimeを年月日、時間に分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['datetime'].dt.year\n",
    "df['month'] = df['datetime'].dt.month\n",
    "df['day'] = df['datetime'].dt.day\n",
    "df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "df['hour'] = df['datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'] = test['datetime'].dt.year\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['day'] = test['datetime'].dt.day\n",
    "test['dayofweek'] = test['datetime'].dt.dayofweek\n",
    "test['hour'] = test['datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価の際に、scikit-learnに用意されているrmse関数を使用するため、logに変換しておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = np.log(df['count'] + 1)\n",
    "df.rename(columns={'count':'rentals'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル作成\n",
    "まずは何も考えず、ランダムフォレストでやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_cols = ['rentals', 'casual', 'registered', 'datetime']\n",
    "feats = [c for c in df.columns if c not in removed_cols]\n",
    "x_train = df[feats]\n",
    "y_train = df['rentals'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestRegressor(random_state=0)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測精度の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logmse(y, pred):\n",
    "    g = mean_squared_error(y, pred)**(1/2)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_train)\n",
    "print(logmse(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "あとはテストデータに対してもpredictして提出用ファイルを作成すればOKです。\n",
    "提出用ファイルの作り方は割愛。  \n",
    "githubに色々とコード載せているので、興味ある方は参照ください。  \n",
    "https://github.com/msk0119/kaggle-bike/blob/master/xgb_cv5.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価方法\n",
    "上で算出した予測精度は、学習データに対する評価スコア。  \n",
    "実際には未知データに対して予測する必要があるため、学習データでテストしてもモデルの汎化能力は評価できない。  \n",
    "そのため、学習データのうち、いくつかのデータを評価用データとする手法で評価を行うのが一般的。\n",
    "#### ホールドアウト法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.30, shuffle = False)#時系列データのためshuffleしない方がいいです。\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "clf.fit(x_trn, y_trn)\n",
    "y_trn_pred = clf.predict(x_trn)\n",
    "y_val_pred = clf.predict(x_val)\n",
    "print(\"trainスコア\", logmse(y_trn, y_trn_pred))\n",
    "print(\"validスコア\", logmse(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### クロスバリデーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=False)\n",
    "\n",
    "list_logmse_score = []\n",
    "\n",
    "for train_idx, valid_idx in kf.split(x_train, y_train):\n",
    "    trn_x = x_train.iloc[train_idx, :]\n",
    "    val_x = x_train.iloc[valid_idx, :]\n",
    "    \n",
    "    trn_y = y_train[train_idx]\n",
    "    val_y = y_train[valid_idx]\n",
    "    \n",
    "    clf = RandomForestRegressor(random_state=0)\n",
    "    clf.fit(trn_x, trn_y)\n",
    "    y_pred = clf.predict(val_x)\n",
    "    \n",
    "    sc_logmse = logmse(val_y, y_pred)\n",
    "    \n",
    "    list_logmse_score.append(sc_logmse)\n",
    "    \n",
    "sc_logmse = np.mean(list_logmse_score)\n",
    "print(list_logmse_score)\n",
    "print(sc_logmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で正しい評価スコアが算出できるため、評価スコアが向上するように、序盤はひたすらにfeature engineeringを頑張るべき。  \n",
    "ある程度いい評価スコアを得られる変数を特定できれば、終盤はハイパーパラメータの探索、モデルのアンサンブル等を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイパーパラメータの探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=False, random_state=0)\n",
    "\n",
    "all_params = {'max_depth': [3, 5, 7],\n",
    "              \"n_estimators\": [10, 100],\n",
    "              'min_samples_split':[2, 4],\n",
    "              'min_samples_leaf':[1, 3],\n",
    "            'random_state':[0]}\n",
    "\n",
    "min_score = 100\n",
    "min_params = None\n",
    "\n",
    "for params in tqdm(list(ParameterGrid(all_params))):\n",
    "    \n",
    "    list_logmse_score = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(x_train, y_train):\n",
    "        trn_x = x_train.iloc[train_idx, :]\n",
    "        val_x = x_train.iloc[valid_idx, :]\n",
    "    \n",
    "        trn_y = y_train[train_idx]\n",
    "        val_y = y_train[valid_idx]\n",
    "    \n",
    "        clf = RandomForestRegressor(**params)\n",
    "        clf.fit(trn_x, trn_y)\n",
    "        y_pred = clf.predict(val_x)\n",
    "    \n",
    "        sc_logmse = logmse(val_y, y_pred)\n",
    "    \n",
    "        list_logmse_score.append(sc_logmse)\n",
    "\n",
    "    sc_logmse = np.mean(list_logmse_score)\n",
    "    if min_score > sc_logmse:\n",
    "        min_score = sc_logmse\n",
    "        min_params = params\n",
    "        \n",
    "print('minimam logmse:',min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
